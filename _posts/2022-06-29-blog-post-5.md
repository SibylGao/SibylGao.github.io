---
title: 'Bev Perception'
date: 2022-06-29
permalink: /posts/2022/06/blog-post-5/
tags:
  - Algorithm
  - Deep learning
  - Transformer
---

学习&参考资料：

+ [Transformer BEV Perception](https://zhuanlan.zhihu.com/p/497434621)

+ [Monocular BEV Perception with Transformers in Autonomous Driving](https://towardsdatascience.com/monocular-bev-perception-with-transformers-in-autonomous-driving-c41e4a893944)  by [Patrick Langechuan Liu](https://medium.com/@patrickllgc?source=post_page-----c41e4a893944--------------------------------)

+ https://github.com/patrick-llgc/Learning-Deep-Learning by Patrick Langechuan Liu
+ https://github.com/chaytonmin/Awesome-BEV-Perception-Multi-Cameras

------



#### Cross-view Transformers for real-time Map-view Semantic Segmentation

contribution：

+ 用隐式的PE来建模不同相机之间的位置关系
+ cross attention
+ 性能在*nuScenes*上SOTA，4xfaster

<img src="post/cross-view-bev.jpg" alt="cross-view-bev" style="zoom:67%;" />

核心是隐式表示cross view，从单应性投影矩阵变换开始推导：

<img src="post/homography.jpg" alt="homography" style="zoom:80%;" />

其中$ \approx$ 是表示scale，相机模型里面这个scale是跟深度相关的一个量，其他向量都用的是齐次坐标，单应性变换建立起了图像坐标系和**世界坐标系**之间的关系，表示成余弦相似度（attention的形式，其实一直不知道这一步是怎么想到的），有：
